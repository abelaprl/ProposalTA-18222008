% ============================================================================================
% BAB III ANALISIS MASALAH
% Pembagian subbab tidak rigid dan dapat bervariasi. Bab ini minimal berisi analisis kebutuhan
% fungsional dan nonfungsional, analisis berbagai alternatif solusi yang dapat ditawarkan, dan
% metode pemilihan solusi yang diusulkan.
% ============================================================================================
\chapter{ANALISIS MASALAH}
\label{chap:analisis-masalah}


\section{Analisis Kondisi Saat Ini}

Perkembangan \textit{large language model} (LLM) dalam beberapa tahun terakhir mendorong pemanfaatan model bahasa dalam berbagai aplikasi, mulai dari penjawab pertanyaan, agen percakapan, hingga sistem pendukung pengambilan keputusan \parencite{bommasani2021opportunities}. Dengan penggunaan yang semakin luas, muncul kebutuhan untuk memahami bagaimana model merespons variasi identitas dan karakteristik pengguna, bukan hanya variasi instruksi tugas. Hal ini penting karena pada praktiknya, interaksi dengan LLM selalu membawa konteks mengenai siapa penggunanya dan dari gaya komunikasi seperti apa instruksi tersebut disampaikan.

Penelitian mengenai persona pada LLM sejauh ini lebih banyak menempatkan persona pada sisi model. Tseng et al.\ mengkaji berbagai pendekatan \textit{role-playing} dan \textit{personalization} yang memberikan identitas tertentu kepada model melalui instruksi sistem \parencite{tseng2024twotales}. Pada pengaturan ini, model diarahkan untuk meniru karakter, gaya bicara, atau peran tertentu, dan evaluasi dilakukan dengan menilai kesesuaian perilaku model terhadap persona tersebut. Fokus semacam ini berbeda dengan skenario ketika persona justru muncul dari sisi pengguna—melalui gaya penulisan, latar belakang yang dinyatakan, atau sinyal sosial lain yang terbawa dalam instruksi.

Di luar skenario \textit{role-playing}, beberapa penelitian menunjukkan bahwa penyisipan persona eksplisit dapat memengaruhi penalaran model, termasuk pada soal penalaran formal yang tidak melibatkan konteks sosial. Gupta et al.\ menemukan bahwa identitas pengguna yang disebutkan dalam instruksi dapat mengubah cara model menyusun langkah penalaran dan memilih jawaban \parencite{gupta2024biasrunsdeep}. Temuan ini menunjukkan bahwa persona tidak hanya memengaruhi pemilihan kosakata atau gaya respons, tetapi juga struktur penalaran yang digunakan model.

Selain itu, penalaran LLM terbukti sensitif terhadap variasi kecil pada formulasi instruksi. Turpin et al.\ memperlihatkan bahwa perubahan ringan pada \textit{prompt} dapat menghasilkan rantai penalaran yang berbeda untuk pertanyaan yang sama \parencite{turpin2023language}. Sensitivitas terhadap framing juga ditunjukkan oleh Zhou et al., yang menemukan bahwa cara instruksi disusun dapat memengaruhi isi maupun gaya jawaban model \parencite{zhou2023largemodelsensitive}. Kombinasi sifat ini membuat analisis persona menjadi lebih menantang, karena persona, framing, dan gaya penulisan sering hadir secara bersamaan dalam sebuah instruksi, sehingga pengaruh masing-masing sulit dipisahkan.

Lapisan kompleksitas lain muncul dari isu bias. Weidinger et al.\ menunjukkan bahwa LLM dapat mencerminkan pola bias sosial yang terdapat pada data pelatihan \parencite{weidinger2021ethical}. Ketika atribut sosial tertentu—seperti profesi, gender, atau latar budaya—muncul dalam instruksi, respons model berpotensi dipengaruhi oleh bias representasional maupun inferensial. Dalam konteks persona, hal ini berarti bahwa variasi respons tidak selalu mencerminkan perubahan kemampuan penalaran, tetapi dapat berasal dari bias yang telah terinternalisasi di dalam model.

Sementara itu, penelitian yang menempatkan persona pada sisi pengguna masih terbatas. Pendekatan pemodelan pengguna, seperti \textit{user language model}, mulai dikembangkan untuk mempelajari variasi bahasa berdasarkan karakteristik pengguna \parencite{naous2025userlm}. Namun, kajian yang secara sistematis menilai pengaruh \textit{user persona}—baik eksplisit maupun implisit—terhadap penalaran dan kualitas jawaban pada berbagai jenis tugas masih belum banyak dilakukan.

Dari sisi teknis, banyak studi persona masih mengandalkan eksekusi manual atau semiotomatis ketika menjalankan eksperimen. Naous et al.\ menyoroti pentingnya mekanisme evaluasi yang terstruktur, termasuk pengelolaan konfigurasi, pencatatan hasil, dan konsistensi skenario pengujian \parencite{naous2025userlm}. Tanpa kerangka evaluasi yang terdokumentasi dengan baik, eksperimen yang melibatkan banyak model, banyak persona, dan berbagai jenis tugas menjadi sulit direplikasi \parencite{naous2025userlm}. Kondisi ini menunjukkan perlunya pendekatan \textit{spec-driven experiment orchestration}, yaitu perancangan eksperimen yang didasarkan pada spesifikasi eksplisit mengenai kombinasi model, persona, dan tugas yang kemudian dijalankan secara otomatis melalui \textit{pipeline} terstruktur.


Berdasarkan kondisi tersebut, masalah-masalah utama yang melatarbelakangi penelitian ini dirangkum pada Tabel~\ref{tab:daftar-masalah-llm-persona}.

\begin{table}[htbp]
  \centering
  \caption{Daftar masalah penelitian terkait \textit{user persona} pada LLM}
  \label{tab:daftar-masalah-llm-persona}
  \footnotesize
  \begin{adjustbox}{max width=\textwidth}
  \begin{tabular}{c p{4.5cm} p{6.5cm}}
    \toprule
    \textbf{Kode} & \textbf{Uraian Masalah} & \textbf{Dampak terhadap Penelitian} \\
    \midrule
    M-01 &
    Persona pada LLM umumnya diterapkan pada sisi model, bukan pada sisi pengguna. &
    Belum ada pemahaman sistematis mengenai bagaimana \textit{user persona} eksplisit maupun implisit memengaruhi penalaran dan kualitas jawaban pada berbagai tugas. \\[0.2cm]
    
    M-02 &
    Efek persona sulit dipisahkan dari efek framing dan gaya penulisan \textit{prompt}. &
    Perubahan performa atau pola penalaran dapat berasal dari variasi formulasi instruksi, bukan semata akibat perubahan \textit{user persona}, sehingga interpretasi hasil menjadi tidak pasti. \\[0.2cm]
    
    M-03 &
    LLM membawa bias sosial yang terinternalisasi dari data pelatihan. &
    Ketika identitas pengguna memuat atribut sosial tertentu, respons model berpotensi mencerminkan bias representasional maupun inferensial, sehingga perbedaan jawaban bisa terkait dengan bias yang sudah ada pada model. \\[0.2cm]
    
    M-04 &
    Cakupan model dan tugas pada studi terdahulu masih terbatas. &
    Analisis sensitivitas terhadap persona sering kali hanya mencakup sedikit model atau jenis tugas, sehingga belum memberikan gambaran yang cukup luas mengenai variasi perilaku LLM di berbagai konteks. \\
    \bottomrule
  \end{tabular}
  \end{adjustbox}
\end{table}

Masalah M-01 berkaitan dengan kecenderungan penelitian sebelumnya yang lebih banyak menempatkan persona pada sisi model. Tseng et al.\ membahas bagaimana persona digunakan untuk mengubah gaya dan peran model melalui instruksi sistem \parencite{tseng2024twotales}. Pendekatan ini berbeda dengan skenario ketika identitas pengguna—baik eksplisit maupun implisit—menjadi bagian dari konteks interaksi. Akibatnya, pengaruh \textit{user persona} terhadap penalaran dan kualitas jawaban belum banyak dikaji secara sistematis.

Masalah M-02 muncul karena struktur penalaran LLM sangat sensitif terhadap variasi kecil dalam formulasi instruksi. Turpin et al.\ menunjukkan bahwa perubahan ringan dalam \textit{prompt} dapat menghasilkan rantai penalaran yang berbeda meskipun pertanyaannya sama \parencite{turpin2023language}. Zhou et al.\ juga memperlihatkan bahwa framing dan gaya penulisan instruksi dapat memengaruhi isi dan gaya jawaban \parencite{zhou2023largemodelsensitive}. Untuk itu, penelitian yang menilai pengaruh persona perlu dirancang sedemikian rupa agar dapat membedakan pengaruh persona dari pengaruh framing.

Masalah M-03 berhubungan dengan bias sosial yang sudah tertanam di dalam model. Weidinger et al.\ menunjukkan bahwa LLM dapat mereproduksi dan memperkuat bias yang terdapat pada data pelatihan \parencite{weidinger2021ethical}. Ketika \textit{user persona} memuat atribut sosial tertentu, respons model dapat dipengaruhi oleh bias tersebut. Hal ini membuat interpretasi hasil menjadi lebih rumit karena variasi jawaban bisa berasal dari interaksi antara persona dan bias model.

Masalah M-04 menyoroti keterbatasan cakupan model dan tugas pada penelitian persona sebelumnya. Banyak studi hanya menguji sedikit model atau fokus pada satu jenis tugas, sehingga belum memberikan gambaran yang lebih luas mengenai bagaimana variasi \textit{user persona} memengaruhi perilaku model pada berbagai kategori tugas \parencite{gupta2024biasrunsdeep, tseng2024twotales}. Kondisi ini membuka peluang untuk merancang eksperimen dengan cakupan multi model dan multi persona.

\section{Analisis Kebutuhan}

\subsection{Identifikasi Masalah Pengguna}

Pengguna dalam penelitian ini adalah peneliti yang ingin mengevaluasi perilaku model bahasa di bawah variasi \textit{user persona}. Berdasarkan kondisi yang telah dibahas sebelumnya, beberapa kebutuhan dasar dapat diidentifikasi sebagai berikut.

\begin{enumerate}
    \item Belum tersedia cara yang terstruktur untuk merumuskan \textit{user persona} eksplisit maupun implisit pada sisi pengguna. Literatur yang ada umumnya berfokus pada persona di sisi model, sehingga peneliti perlu menyusun sendiri definisi persona yang diperlukan dalam eksperimen.
    
    \item Perbedaan respons model dapat dipengaruhi oleh variasi kecil pada formulasi pertanyaan. Hal ini menyulitkan proses analisis, karena tidak selalu jelas apakah perubahan jawaban disebabkan oleh persona atau oleh perbedaan cara instruksi disampaikan.
    
    \item Eksperimen yang melibatkan lebih dari satu model dan beberapa kategori tugas membutuhkan prosedur yang memungkinkan skenario yang sama dijalankan kembali dan hasilnya dicatat secara konsisten, sehingga perbandingan antar kondisi dapat dilakukan secara sistematis.
\end{enumerate}

Identifikasi ini menjadi dasar penyusunan kebutuhan fungsional dan nonfungsional penelitian.

\subsection{Kebutuhan Fungsional}

Kebutuhan fungsional merujuk pada kemampuan yang perlu tersedia agar eksperimen dapat berjalan sesuai tujuan. Kebutuhan tersebut ditampilkan pada Tabel~\ref{tab:kebutuhan-fungsional-llm-persona}.

\begin{table}[htbp]
  \centering
  \caption{Kebutuhan fungsional penelitian}
  \label{tab:kebutuhan-fungsional-llm-persona}
  \begin{tabular}{p{1.5cm}p{8cm}p{3.5cm}}
    \toprule
    Kode & Uraian kebutuhan fungsional & Terkait masalah \\
    \midrule
    KF-01 &
    Mekanisme untuk mendefinisikan \textit{user persona} eksplisit dan implisit dalam bentuk skenario teks yang seragam, sehingga persona dapat dirancang secara konsisten dan digunakan kembali. &
    M-01 \\[0.2cm]
    
    KF-02 &
    Mekanisme untuk menjalankan pertanyaan yang sama pada beberapa persona dan beberapa model, serta mencatat respons berikut informasi persona, model, dan jenis tugas. &
    M-02, M-04 \\[0.2cm]
    
    KF-03 &
    Format pencatatan hasil yang mendukung penilaian sederhana seperti benar–salah dan indikasi bias, sehingga keluaran model dapat dianalisis lebih lanjut tanpa perlakuan tambahan yang kompleks. &
    M-03, M-04 \\

    KF-04 &
Mendukung eksekusi eksperimen berbasis konfigurasi (\textit{spec-driven execution}), 
di mana daftar model, persona, benchmark, serta parameter eksekusi disusun dalam 
satu berkas spesifikasi yang dapat dibaca otomatis oleh \textit{pipeline}. 
Pendekatan ini memastikan bahwa perubahan skenario eksperimen tidak memerlukan 
modifikasi kode. &
M-02, M-04 \\[0.2cm]

    \bottomrule
  \end{tabular}
\end{table}

Penjelasan singkat atas kebutuhan fungsional adalah sebagai berikut.

KF-01 menyediakan mekanisme untuk menyusun \textit{user persona} eksplisit 
dan implisit secara terstandar, sehingga persona dapat digunakan ulang 
dan dibandingkan secara konsisten.

KF-02 memastikan bahwa pertanyaan yang sama dapat dijalankan pada beberapa 
persona dan beberapa model, serta seluruh keluaran dicatat bersama metadata, 
memungkinkan analisis komparatif yang terstruktur.

KF-03 menyediakan format pencatatan hasil yang mendukung evaluasi benar–salah 
dan indikasi bias, sehingga keluaran model dapat dianalisis tanpa proses 
pengolahan tambahan yang kompleks.

KF-04 mendukung pendekatan \textit{spec-driven execution}, di mana seluruh 
kombinasi model, persona, dan benchmark dikendalikan melalui satu berkas 
spesifikasi, sehingga eksperimen dapat direproduksi dan dimodifikasi tanpa 
mengubah kode.

\subsection{Kebutuhan Nonfungsional}

Kebutuhan nonfungsional berkaitan dengan kualitas pelaksanaan eksperimen dan sifat teknis dari kerangka kerja yang digunakan. Daftar kebutuhan nonfungsional ditunjukkan pada Tabel~\ref{tab:kebutuhan-nonfungsional-llm-persona}.

\begin{table}[htbp]
  \centering
  \caption{Kebutuhan nonfungsional penelitian}
  \label{tab:kebutuhan-nonfungsional-llm-persona}
  \begin{tabular}{p{1.5cm}p{3.5cm}p{8cm}}
    \toprule
    Kode & Jenis kebutuhan & Uraian kebutuhan \\
    \midrule
    KNF-01 &
    Reproducibility &
    Seluruh rangkaian eksperimen dapat dijalankan ulang melalui skrip atau konfigurasi yang terdokumentasi, sehingga model, persona, dan tugas dapat diuji kembali dalam kondisi yang serupa. \\[0.2cm]
    
    KNF-02 &
    Simplicity &
    Pelaksanaan eksperimen dapat dilakukan dengan langkah-langkah yang langsung dan tidak memerlukan infrastruktur tambahan di luar pemanggilan API atau prosedur serupa. \\[0.2cm]
    
    KNF-03 &
    Extensibility &
    Struktur eksperimen memungkinkan penambahan model atau persona baru tanpa perubahan besar pada kerangka yang sudah ada, sehingga penelitian dapat dikembangkan lebih lanjut sesuai kebutuhan. \\
    
    KNF-04 &
    Configuration-driven design &
    Seluruh eksperimen dikendalikan melalui satu berkas spesifikasi 
    (\textit{experiment specification}) yang mengatur model, persona, benchmark, 
    parameter eksekusi, serta struktur prompt. Pendekatan ini memastikan 
    reproducibility, konsistensi lintas percobaan, serta kemudahan dalam 
    mengubah atau memperluas skenario eksperimen tanpa mengubah kode. \\ 


    \bottomrule
  \end{tabular}
\end{table}

Penjelasan singkat atas kebutuhan nonfungsional tersebut adalah sebagai berikut.

KNF-01 (Reproducibility) memastikan bahwa eksperimen dapat diulang dalam 
kondisi yang sama, sehingga perbedaan keluaran dapat ditelusuri secara jelas 
ke variasi persona.

KNF-02 (Simplicity) menjaga agar proses eksekusi tetap sederhana tanpa 
ketergantungan infrastruktur tambahan, sehingga fokus penelitian berada pada 
analisis hasil.

KNF-03 (Extensibility) memungkinkan penambahan model, persona, atau benchmark 
baru tanpa perubahan besar pada kode, sehingga penelitian dapat dikembangkan 
lebih lanjut.

KNF-04 (Configuration-driven) memastikan bahwa seluruh eksperimen dikendalikan 
melalui satu berkas spesifikasi, sehingga skenario \textit{multi model} 
$\times$ \textit{multi persona} $\times$ \textit{multi benchmark} dapat 
dikelola dan direproduksi secara konsisten.

\section{Analisis Pemilihan Solusi}

Bagian ini membahas alternatif pendekatan yang dapat digunakan untuk melaksanakan eksperimen \textit{multi model} dan \textit{multi persona}, kemudian menjelaskan dasar pemilihan solusi yang digunakan dalam penelitian. Analisis dilakukan dengan mempertimbangkan kebutuhan representasi \textit{user persona}, konsistensi eksekusi lintas model dan tugas, kemudahan pencatatan hasil, serta tingkat kerumitan implementasi.

\subsection{Alternatif Solusi}

Berdasarkan kebutuhan yang telah dirumuskan pada Subbagian~3.2, beberapa alternatif solusi yang dapat dipertimbangkan adalah sebagai berikut.

\begin{enumerate}
    \item Evaluasi manual melalui antarmuka percakapan.
    
    Interaksi dengan \textit{large language model} dilakukan langsung melalui antarmuka percakapan yang disediakan oleh penyedia layanan. \textit{User persona} disisipkan ke dalam instruksi, pertanyaan dijalankan satu per satu, dan hasil dicatat secara manual. Alternatif ini mudah digunakan pada tahap awal, tetapi tidak efisien ketika jumlah kombinasi skenario menjadi besar. Prosesnya rentan terhadap variasi formulasi instruksi dan bergantung pada ketelitian pencatatan, sehingga menyulitkan replikasi dengan kondisi yang sama.
    
    \item Skrip eksperimen semi terotomatisasi berbasis konfigurasi.
    
Pada alternatif ini, daftar persona, model, dan kumpulan tugas (misalnya GSM8K dan MMLU-Redux) disimpan dalam berkas konfigurasi yang terstruktur. Skrip eksperimen membaca konfigurasi tersebut, menyusun \textit{prompt} untuk setiap kombinasi skenario, memanggil model melalui API, lalu menyimpan keluaran beserta metadata ke dalam berkas JSON. Tahap analisis kemudian mengolah JSON menjadi keluaran yang lebih ringkas, seperti CSV, untuk perhitungan metrik dan evaluasi lanjutan. Pendekatan ini memerlukan penulisan skrip, tetapi memberikan struktur yang rapi, mendukung eksekusi dalam jumlah besar, dan secara praktis merealisasikan gagasan \textit{spec-driven experiment orchestration} karena seluruh ruang eksperimen diturunkan dari spesifikasi konfigurasi.
    
    \item Kerangka evaluasi umum yang dapat digunakan kembali.
    
    Alternatif ini merupakan perluasan dari pendekatan kedua dengan membangun kerangka evaluasi yang lebih lengkap, misalnya berupa pustaka atau layanan khusus. Fitur yang disediakan dapat mencakup penjadwalan eksekusi, pengelolaan versi konfigurasi, penilaian otomatis, hingga visualisasi hasil. Pendekatan ini cenderung lebih fleksibel untuk penggunaan jangka panjang, tetapi memerlukan usaha perancangan dan implementasi yang cukup besar untuk konteks tugas akhir.
\end{enumerate}

\subsection{Analisis Penentuan Solusi}

Ketiga alternatif dibandingkan berdasarkan beberapa kriteria, yaitu kemampuan merepresentasikan skenario eksperimen secara terstruktur, konsistensi eksekusi, dukungan pencatatan metadata, keterulangan (\textit{reproducibility}), tingkat kerumitan implementasi, serta kemudahan menambahkan model atau persona baru. Ringkasan perbandingan ditunjukkan pada Tabel~\ref{tab:analisis-pemilihan-solusi}.

\begin{table}[htbp]
  \centering
  \caption{Perbandingan alternatif solusi}
  \label{tab:analisis-pemilihan-solusi}
  \footnotesize
  \begin{adjustbox}{max width=\textwidth}
  \begin{tabular}{p{4.5cm}ccc}
    \toprule
    \textbf{Kriteria} &
    \textbf{Evaluasi Manual} &
    \textbf{Skrip Semi-Otomatis} &
    \textbf{Kerangka Evaluasi Umum} \\
    \midrule
    Representasi \textit{user persona} dan skenario terstruktur &
    Rendah & Tinggi & Tinggi \\[0.15cm]
    
    Konsistensi eksekusi lintas model dan tugas &
    Rendah & Tinggi & Tinggi \\[0.15cm]
    
    Pencatatan hasil dan metadata &
    Rendah & Tinggi & Tinggi \\[0.15cm]
    
    Keterulangan eksperimen &
    Rendah & Tinggi & Tinggi \\[0.15cm]
    
    Kerumitan implementasi dan pemeliharaan &
    Rendah & Sedang & Tinggi \\[0.15cm]
    
    Kemudahan penambahan model atau persona baru &
    Rendah & Tinggi & Tinggi \\
    \bottomrule
  \end{tabular}
  \end{adjustbox}
\end{table}

Pendekatan evaluasi manual mudah digunakan, tetapi tidak memenuhi kebutuhan eksperimen dengan banyak kombinasi model dan persona. Keterbatasan terutama terlihat pada konsistensi eksekusi, dokumentasi hasil, serta kesulitan mengulang percobaan dengan kondisi identik.

Pendekatan kerangka evaluasi umum menyediakan fleksibilitas yang lebih luas, tetapi memerlukan usaha perancangan dan implementasi yang cukup besar. Beban tersebut dapat mengalihkan fokus dari tujuan utama penelitian.

Pendekatan skrip eksperimen semi terotomatisasi berbasis konfigurasi menawarkan keseimbangan yang paling sesuai. Representasi model, persona, dan tugas dapat diatur dalam direktori konfigurasi, sedangkan proses eksekusi dan analisis dijalankan melalui skrip yang konsisten. Seluruh keluaran disimpan dalam format terstruktur sehingga mudah dianalisis kembali. Struktur seperti ini mendukung keterulangan eksperimen dan perluasan skenario tanpa memerlukan pembangunan kerangka yang kompleks.

Berdasarkan pertimbangan tersebut, penelitian ini menggunakan pendekatan skrip eksperimen semi terotomatisasi berbasis konfigurasi sebagai solusi utama dalam melaksanakan eksperimen \textit{multi model} dan \textit{multi persona}. Dalam konteks penelitian ini, pendekatan tersebut diimplementasikan sebagai \textit{spec-driven experiment orchestration}, di mana konfigurasi model, persona, dan benchmark didefinisikan terlebih dahulu dalam bentuk spesifikasi sebelum dieksekusi secara otomatis oleh \textit{pipeline}.
