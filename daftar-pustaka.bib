@inproceedings{gupta2024biasrunsdeep,
  title        = {Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned Language Models},
  author       = {Gupta, Shashank and Shrivastava, Vaishnavi and Deshpande, Ameet and Kalyan, Ashwin and Clark, Peter and Sabharwal, Ashish and Khot, Tushar},
  booktitle    = {Proceedings of the Twelfth International Conference on Learning Representations},
  year         = {2024},
  url          = {https://openreview.net/forum?id=kGteeZ18Ir}
}

@inproceedings{tseng2024twotales,
  title        = {Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization},
  author       = {Tseng, Yu-Min and Huang, Yu-Chao and Hsiao, Teng-Yun and Chen, Wei-Lin and Huang, Chao-Wei and Meng, Yu and Chen, Yun-Nung},
  booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  year         = {2024},
  pages        = {16612--16631},
  url          = {https://aclanthology.org/2024.findings-emnlp.969}
}

@article{naous2025userlm,
  title        = {Training and Evaluating User Language Models},
  author       = {Naous, Tarek and Roziere, Baptiste and others},
  journal      = {arXiv preprint arXiv:2510.06552},
  year         = {2025},
  url          = {https://arxiv.org/abs/2510.06552}
}

@article{weidinger2021ethical,
  title        = {Ethical and Social Risks of Harm from Language Models},
  author       = {Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Christopher and Gabriel, Iason and Uesato, Jonathan and Huang, Po-Sen and Kenton, Zachary and Brown, Tom B. and others},
  journal      = {arXiv preprint arXiv:2112.04359},
  year         = {2021},
  url          = {https://arxiv.org/abs/2112.04359}
}

@article{bommasani2021opportunities,
  title        = {On the Opportunities and Risks of Foundation Models},
  author       = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and others},
  journal      = {arXiv preprint arXiv:2108.07258},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.07258}
}

@article{turpin2023language,
  title        = {Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Reasoning},
  author       = {Turpin, Miles and others},
  journal      = {arXiv preprint arXiv:2305.04388},
  year         = {2023},
  url          = {https://arxiv.org/abs/2305.04388}
}

@article{zhou2023largemodelsensitive,
  title        = {Large Language Models Are Sensitive to Prompt Framing},
  author       = {Zhou, Luozhi and others},
  journal      = {arXiv preprint arXiv:2310.05400},
  year         = {2023},
  url          = {https://arxiv.org/abs/2310.05400}
}

@inproceedings{zhao2021calibrate,
  title        = {Calibrate Before Use: Improving Few-Shot Performance of Language Models},
  author       = {Zhao, Yanhao and Wallace, Eric and Feng, Shi and Singh, Mohit and Gardner, Matt},
  booktitle    = {Proceedings of the International Conference on Machine Learning},
  year         = {2021},
  pages        = {12697--12706}
}
