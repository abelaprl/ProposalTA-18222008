@inproceedings{gupta2024biasrunsdeep,
  title        = {Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned Language Models},
  author       = {Gupta, Shashank and Shrivastava, Vaishnavi and Deshpande, Ameet and Kalyan, Ashwin and Clark, Peter and Sabharwal, Ashish and Khot, Tushar},
  booktitle    = {Proceedings of the Twelfth International Conference on Learning Representations},
  year         = {2024},
  url          = {https://openreview.net/forum?id=kGteeZ18Ir}
}

@inproceedings{tseng2024twotales,
  title        = {Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization},
  author       = {Tseng, Yu-Min and Huang, Yu-Chao and Hsiao, Teng-Yun and Chen, Wei-Lin and Huang, Chao-Wei and Meng, Yu and Chen, Yun-Nung},
  booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  year         = {2024},
  pages        = {16612--16631},
  url          = {https://aclanthology.org/2024.findings-emnlp.969}
}

@article{naous2025userlm,
  title        = {Training and Evaluating User Language Models},
  author       = {Naous, Tarek and Roziere, Baptiste and others},
  journal      = {arXiv preprint arXiv:2510.06552},
  year         = {2025},
  url          = {https://arxiv.org/abs/2510.06552}
}

@article{weidinger2021ethical,
  title        = {Ethical and Social Risks of Harm from Language Models},
  author       = {Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Christopher and Gabriel, Iason and Uesato, Jonathan and Huang, Po-Sen and Kenton, Zachary and Brown, Tom B. and others},
  journal      = {arXiv preprint arXiv:2112.04359},
  year         = {2021},
  url          = {https://arxiv.org/abs/2112.04359}
}

@article{bommasani2021opportunities,
  title        = {On the Opportunities and Risks of Foundation Models},
  author       = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and others},
  journal      = {arXiv preprint arXiv:2108.07258},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.07258}
}

@article{turpin2023language,
  title        = {Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Reasoning},
  author       = {Turpin, Miles and others},
  journal      = {arXiv preprint arXiv:2305.04388},
  year         = {2023},
  url          = {https://arxiv.org/abs/2305.04388}
}

@article{zhou2023largemodelsensitive,
  title        = {Large Language Models Are Sensitive to Prompt Framing},
  author       = {Zhou, Luozhi and others},
  journal      = {arXiv preprint arXiv:2310.05400},
  year         = {2023},
  url          = {https://arxiv.org/abs/2310.05400}
}

@inproceedings{zhao2021calibrate,
  title        = {Calibrate Before Use: Improving Few-Shot Performance of Language Models},
  author       = {Zhao, Yanhao and Wallace, Eric and Feng, Shi and Singh, Mohit and Gardner, Matt},
  booktitle    = {Proceedings of the International Conference on Machine Learning},
  year         = {2021},
  pages        = {12697--12706}
}

@article{cobbe2021gsm8k,
  author  = {Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and
             Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and
             Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
  title   = {Training Verifiers to Solve Math Word Problems},
  journal = {arXiv preprint arXiv:2110.14168},
  year    = {2021},
  url     = {https://arxiv.org/abs/2110.14168}
}

@article{hendryckstest2021,
  author  = {Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and
             Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  title   = {Measuring Massive Multitask Language Understanding},
  journal = {International Conference on Learning Representations},
  year    = {2021},
  url     = {https://arxiv.org/abs/2009.03300}
}


@inproceedings{sap2019socialiqa,
  author    = {Maarten Sap and Hannah Rashkin and Derek Chen and Ronan Le Bras and Yejin Choi},
  title     = {SocialIQA: Commonsense Reasoning about Social Interactions},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
               and the 9th International Joint Conference on Natural Language Processing},
  year      = {2019},
  address   = {Hong Kong, China},
  url       = {https://arxiv.org/abs/1904.09728}
}

@article{gema2024arewedonewithmmlu,
  author  = {Aryo Pradipta Gema and Joshua Ong Jun Leang and Giwon Hong and
             Alessio Devoto and others},
  title   = {Are We Done with MMLU?},
  journal = {arXiv preprint arXiv:2406.04127},
  year    = {2024},
  url     = {https://arxiv.org/abs/2406.04127}
}


@misc{mmluRedux2024dataset,
  author       = {{Edinburgh Dataset Analytics Working Group}},
  title        = {MMLU-Redux 2.0 Dataset},
  year         = {2024},
  howpublished = {\url{https://huggingface.co/datasets/edinburgh-dawg/mmlu-redux-2.0}},
  note         = {Versi kurasi ulang MMLU dengan 57 subjek dan 100 butir soal per subjek}
}

@article{liang2023helm,
  title={Holistic Evaluation of Language Models},
  author={Liang, P. and Bommasani, R. and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2023},
  url={https://arxiv.org/abs/2211.09110}
}

BIBTEX REFERENSI SUBBAB 2.1 (LENGKAP)
@inproceedings{bengio2003nlm,
  title     = {A Neural Probabilistic Language Model},
  author    = {Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  booktitle = {Journal of Machine Learning Research},
  year      = {2003},
  volume    = {3},
  pages     = {1137--1155}
}

@book{goodfellow2016deep,
  title     = {Deep Learning},
  author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  publisher = {MIT Press},
  year      = {2016},
  url       = {https://www.deeplearningbook.org}
}

@inproceedings{vaswani2017attention,
  title     = {Attention Is All You Need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob 
               and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017}
}

@article{brown2020language,
  title   = {Language Models are Few-Shot Learners},
  author  = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared 
             and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish 
             and others},
  journal = {Advances in Neural Information Processing Systems},
  year    = {2020}
}

@article{liu2024lost,
  title     = {Lost in the Middle: How Language Models Use Long Contexts},
  author    = {Liu, Nelson F and others},
  journal   = {Transactions of the Association for Computational Linguistics},
  year      = {2024},
  url       = {https://arxiv.org/abs/2307.03172}
}

@inproceedings{ranzato2016sequence,
  title     = {Sequence Level Training with Recurrent Neural Networks},
  author    = {Ranzato, Marc'Aurelio and Chopra, Sumit and Auli, Michael and Zaremba, Wojciech},
  booktitle = {International Conference on Learning Representations},
  year      = {2016},
  url       = {https://arxiv.org/abs/1511.06732}
}

@inproceedings{bender2021stochastic,
  title     = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author    = {Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Mitchell, Margaret},
  booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  year      = {2021},
  doi       = {10.1145/3442188.3445922}
}

@article{ouyang2022training,
  title  = {Training Language Models to Follow Instructions with Human Feedback},
  author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and others},
  journal = {arXiv preprint arXiv:2203.02155},
  year   = {2022},
  url    = {https://arxiv.org/abs/2203.02155}
}



%% ========== MODEL & API PRICING REFERENCES ==========
@misc{openrouter_gpt5mini,
  title={OpenAI GPT-5 Mini Pricing},
  howpublished={\url{https://openrouter.ai/openai/gpt-5-mini}},
  note={Diakses 2025}
}


@misc{openrouter_gemini25flash,
  title={Google Gemini 2.5 Flash Pricing},
  howpublished={\url{https://openrouter.ai/google/gemini-2.5-flash}},
  note={Diakses 2025}
}

@misc{openrouter_deepseek32,
  title={DeepSeek V3.2 Pricing},
  howpublished={\url{https://openrouter.ai/deepseek/deepseek-v3.2}},
  note={Diakses 2025}
}

@misc{openrouter_llama33,
  title={NVIDIA Llama 3.3 Nemotron Super 49B V1.5 Pricing},
  howpublished={\url{https://openrouter.ai/nvidia/llama-3.3-nemotron-super-49b-v1.5}},
  note={Diakses 2025}
}

@misc{openrouter_gemma3n,
  title={Google Gemma 3n 4B Pricing},
  howpublished={\url{https://openrouter.ai/google/gemma-3n-e4b-it}},
  note={Diakses 2025}
}
@misc{openrouter_qwen3vl30ba3b,
  title        = {Qwen3 VL 30B A3B Instruct},
  author       = {Qwen Team},
  year         = {2025},
  howpublished = {\url{https://openrouter.ai/models/qwen/qwen3-vl-30b-a3b-instruct}},
  note         = {262{,}144 context window. Pricing: \$0.15/M input tokens, \$0.60/M output tokens. Created October 6, 2025.},
}
