% ==========================================
% BAB IV DESAIN KONSEP SOLUSI
% ==========================================

\chapter{DESAIN KONSEP SOLUSI}
\label{chap:desain-konsep-solusi}
Bab ini menguraikan rancangan solusi yang digunakan untuk melaksanakan eksperimen
multi-model dan multi-persona pada tugas penalaran. Pembahasan dimulai dari desain
konseptual eksperimen, diikuti arsitektur dan alur kerja \textit{evaluation pipeline},
integrasi komponen-komponen utama (persona, model, dan \textit{benchmark}),
perancangan struktur data dan berkas, hingga mekanisme penanganan gangguan serta
bentuk keluaran yang dihasilkan untuk analisis pada bab berikutnya.

\section{Desain Konseptual Eksperimen}

Bagian ini menjelaskan landasan perancangan eksperimen yang digunakan dalam penelitian. Desain ini disusun untuk melihat bagaimana dua bentuk persona, yaitu persona eksplisit dan persona implisit, memengaruhi hasil keluaran pada beberapa kategori tugas penalaran dan beberapa sistem yang berbeda. Penyusunan bagian ini dimaksudkan untuk memastikan bahwa setiap variasi yang muncul dapat ditelusuri kembali pada kondisi persona yang digunakan, bukan pada perbedaan situasi pengujian atau susunan instruksi.

\subsection{Tujuan Perancangan Eksperimen}

Perancangan eksperimen dilakukan untuk menyediakan kerangka yang memungkinkan perbandingan persona secara terarah. Dua bentuk persona digunakan karena mewakili dua pola interaksi yang umum terjadi, yaitu ketika identitas pengguna dinyatakan secara langsung serta ketika identitas tersebut tersirat melalui cara bertutur. Kerangka ini juga dirancang agar dapat digunakan untuk membandingkan respons dari beberapa sistem secara konsisten pada jenis tugas yang sama.

\subsection{Komponen Utama Eksperimen}

Eksperimen yang dilakukan mengombinasikan tiga komponen utama, yaitu persona, sistem, dan tugas penalaran.  
Persona mencakup bentuk eksplisit dan implisit, yang masing-masing memberikan konteks pengguna dengan kedalaman dan cara penyampaian yang berbeda.  
Komponen sistem terdiri atas beberapa model yang tersedia melalui layanan API sehingga memungkinkan analisis lintas arsitektur.  
Tugas penalaran yang digunakan mencakup penalaran numerik dan penalaran lintas topik untuk melihat bagaimana bentuk persona memengaruhi keluaran pada sifat tugas yang berbeda.

\subsection{Spec-Driven Experiment Orchestration}

Penelitian ini menggunakan pendekatan \textit{spec-driven experiment orchestration},
yaitu metode di mana seluruh eksperimen dikendalikan melalui satu berkas spesifikasi
(\textit{spec}) yang mendefinisikan daftar model, persona, benchmark, serta parameter
eksekusi. Spec ini menjadi \textit{single source of truth} yang memastikan bahwa seluruh
kombinasi skenario dijalankan secara konsisten dan dapat direproduksi.

\subsubsection{Isi dan Struktur Spec}

Berkas spec memuat empat komponen utama:

\begin{enumerate}
    \item Daftar model: mencakup ID model, nama model, dan \textit{provider}.
    \item Daftar persona: mencakup persona eksplisit, implisit, dan netral.
    \item Daftar benchmark: termasuk \textit{dataset}, \textit{split}, dan subjek.
    \item Ruang skenario: kombinasi 
          \textit{model} $\times$ \textit{persona} $\times$ \textit{benchmark} 
          yang harus dieksekusi oleh pipeline.
\end{enumerate}

Keempat komponen ini menjadikan spec sebagai konfigurasi lengkap mengenai eksperimen
tanpa perlu menyunting kode program.

\subsubsection{Contoh Spec Eksperimen}

Listing~\ref{lst:spec-example} menunjukkan contoh berkas YAML yang akan digunakan
dalam penelitian ini.

\begin{lstlisting}[language=yaml,caption={Contoh ringkas berkas spesifikasi eksperimen},label={lst:spec-example}]
experiment_id: persona-reasoning-eval-v1

models:
  - id: llama-3-8b
    provider: groq
  - id: gpt-4.1-mini
    provider: openrouter

personas:
  - id: explicit_woman_student
    type: explicit
  - id: implicit_woman_student
    type: implicit
  - id: neutral
    type: neutral

benchmarks:
  - id: gsm8k
    split: test
  - id: mmlu-redux
    subjects:
      - sociology
      - abstract_algebra

scenarios:
  - model: llama-3-8b
    persona: explicit_woman_student
    benchmark: gsm8k

  - model: llama-3-8b
    persona: neutral
    benchmark: gsm8k

  - model: gpt-4.1-mini
    persona: implicit_woman_student
    benchmark: mmlu-redux
\end{lstlisting}

\subsubsection{Peran Spec dalam Pipeline}

Pipeline eksperimen membaca berkas spec dan:

\begin{enumerate}
    \item menghasilkan daftar lengkap kombinasi skenario,
    \item menyiapkan persona sesuai konfigurasi,
    \item menyusun prompt secara konsisten untuk seluruh model,
    \item mengeksekusi seluruh skenario secara otomatis,
    \item menyimpan keluaran model beserta metadata konfigurasi.
\end{enumerate}

Pendekatan ini memenuhi kebutuhan KF-04 dan KNF-04 karena:

\begin{itemize}
    \item eksperimen dapat diubah atau diperluas hanya dengan memodifikasi isi spec
          tanpa mengubah kode,
    \item struktur prompt dan alur eksekusi tetap seragam untuk seluruh model dan persona,
    \item seluruh kombinasi \textit{multi model} $\times$ \textit{multi persona}
          $\times$ \textit{multi benchmark} dapat dijalankan otomatis,
    \item setiap hasil eksperimen dapat ditelusuri ulang ke konfigurasi yang jelas,
          terdokumentasi, dan dapat direproduksi.
\end{itemize}

Dengan demikian, spec berfungsi sebagai unit kontrol utama dalam desain eksperimen
dan memastikan bahwa pipeline berjalan secara terstruktur, konsisten, dan replikatif.


\subsection{Prinsip Pengendalian Variabel}

Untuk menjaga kesetaraan pengujian, seluruh instruksi disampaikan menggunakan susunan yang seragam pada setiap kombinasi persona, sistem, dan tugas. Dengan demikian, unsur yang bervariasi hanyalah bentuk persona. Pendekatan ini dilakukan agar hasil yang diperoleh dapat dibandingkan secara langsung tanpa dipengaruhi oleh variasi lain di luar persona.

\subsection{Ruang Konfigurasi}

Ruang eksperimen dibentuk berdasarkan kombinasi antara persona, sistem, dan tugas penalaran. Setiap elemen didefinisikan melalui berkas konfigurasi sehingga struktur ruang eksperimen terdokumentasi dengan jelas dan dapat diperluas apabila diperlukan. Dengan adanya pengaturan ini, seluruh kondisi yang diuji dapat ditelusuri kembali dan dianalisis berdasarkan konfigurasi yang digunakan.

\subsection{Keterkaitan dengan Pelaksanaan Eksperimen}

Desain konseptual ini menjadi dasar bagi alur pelaksanaan yang dibahas pada bagian berikutnya. Dengan pemisahan antara tahap perancangan dan tahap pelaksanaan, eksperimen dapat dijalankan secara teratur dan seluruh hasil yang diperoleh dapat dianalisis kembali pada bab selanjutnya.


%====== BAB IV.2 ======
\section{Arsitektur \textit{Evaluation Pipeline} dan Alur Pelaksanaan Eksperimen}
\label{sec:arsitektur-dan-alur}

Bagian ini menjelaskan bagaimana rancangan konseptual pada Subbab sebelumnya direalisasikan dalam bentuk arsitektur \textit{evaluation pipeline} yang terotomatisasi, serta bagaimana pipeline tersebut menjalankan alur eksperimen dari pemuatan \textit{specification} hingga diperolehnya keluaran akhir. Pendekatan ini dirancang agar proses evaluasi berjalan secara otomatis, konsisten, dan dapat direproduksi, sehingga setiap kombinasi persona, model, dan \textit{benchmark task} diuji dalam kondisi yang setara dan bebas dari variasi yang tidak diperlukan.

Pipeline bekerja sebagai rangkaian komponen yang saling berinteraksi, mulai dari pemuatan data, konstruksi instruksi, pengiriman permintaan ke model, hingga pencatatan \textit{telemetry}. Seluruh proses tersebut membentuk satu alur terintegrasi yang mampu menangani jumlah evaluasi besar secara stabil.

\subsection{Arsitektur Alur Kerja Sistem}
\label{subsec:arsitektur-alur-kerja}

Secara garis besar, \textit{evaluation pipeline} terbagi ke dalam empat komponen utama yang membentuk satu siklus pemrosesan berulang untuk setiap kombinasi persona dan butir soal. Keempat komponen tersebut adalah sebagai berikut.

\begin{enumerate}
    \item \textit{Configuration initialization and validation}.\\
    Tahap ini memuat seluruh konfigurasi sistem, definisi persona, dan \textit{benchmark dataset} ke dalam memori. Struktur data yang dibaca dari berkas \textit{specification} (persona, model, dan \textit{task}) divalidasi untuk memastikan bahwa setiap persona memiliki \textit{system instruction} yang lengkap dan setiap butir tugas memiliki pasangan pertanyaan dan jawaban acuan.

    \item \textit{Prompt construction engine}.\\
    Sistem membentuk \textit{system message} yang berisi identitas persona serta \textit{user message} yang memuat pertanyaan dari \textit{benchmark}. Seluruh instruksi dirumuskan secara seragam untuk menjaga konsistensi antar kondisi.

    \item \textit{Execution manager}.\\
    Komponen ini menangani pemanggilan API menggunakan eksekusi asinkron berbasis \textit{I/O concurrency}. Permintaan ditempatkan dalam \textit{task queue} dan dijalankan dalam batch sesuai batas \textit{rate limit} layanan model.

    \item \textit{Telemetry logger}.\\
    Komponen terakhir bertugas menyimpan seluruh keluaran model, termasuk teks jawaban, jawaban akhir yang diekstraksi, jumlah token, serta \textit{latency} inferensi.
\end{enumerate}

Dengan pembagian tersebut, pipeline dapat beroperasi secara modular namun tetap terpadu dalam satu alur pemrosesan yang deterministik.

\subsection{Algoritma Orkestrasi dan Konkurensi}
\label{subsec:algoritma-orkestrasi}

Eksperimen melibatkan ribuan kombinasi persona–model–pertanyaan sehingga volume permintaan API menjadi sangat besar. Eksekusi sekuensial tidak praktis karena setiap permintaan memiliki latensi yang berbeda dan layanan API menerapkan batas \textit{rate limit}. Untuk itu, pipeline menggunakan eksekusi asinkron berbasis \textit{I/O concurrency}.

Pendekatan ini menurunkan waktu total dari kompleksitas \(O(N)\) menjadi mendekati \(O(N/C)\), dengan \(C\) adalah kapasitas konkurensi. Pipeline juga menerapkan \textit{exponential backoff} untuk menangani galat seperti \textit{timeout} atau \texttt{429 Too Many Requests}.

Kode~\ref{lst:algoritma-eksperimen} berikut merumuskan prosedur orkestrasi secara formal.

\begin{lstlisting}[caption={Prosedur eksekusi eksperimen paralel}, label={lst:algoritma-eksperimen}]
Input : Himpunan Persona P, Himpunan Tugas T, Batas Konkurensi C
Output: Himpunan Log L

Function RunExperiment(P, T):
  1. Q <- Queue kosong
  2. Untuk setiap p dalam P:
       Untuk setiap t dalam T:
         prompt <- ConstructPrompt(p, t)
         Enqueue(Q, prompt)

  3. S <- Semaphore(C)

  4. While Q tidak kosong (asinkron):
       batch <- DequeueBatch(Q, C)
       Untuk setiap item i dalam batch (paralel):
         Acquire(S)
         Try:
           resp <- AsyncCallAPI(i)
           meta <- ExtractTelemetry(resp)
           SaveLog(resp, meta)
         Catch error:
           RetryWithBackoff(i)
         Finally:
           Release(S)

  5. Return L
\end{lstlisting}

\subsection{Pseudocode Eksekusi Batch Benchmark GSM8K dan MMLU-Redux}
\label{subsec:pseudocode-benchmark}

Untuk merealisasikan algoritma orkestrasi tersebut, pipeline menggunakan sebuah prosedur generik bernama \texttt{RunBenchmarkBatch}. Berbeda dari implementasi awal yang memisahkan GSM8K dan MMLU-Redux, pipeline pada penelitian ini menggabungkan keduanya ke dalam satu algoritma yang menangani dua format evaluasi:  
(1) jawaban numerik bebas (GSM8K) dan  
(2) pilihan ganda (MMLU-Redux).

Pseudocode berikut merangkum alur lengkap yang diterapkan pada kedua \textit{benchmark}.

\begin{lstlisting}[caption={Pseudocode prosedur eksekusi batch untuk GSM8K dan MMLU-Redux},label={lst:run-benchmark-batch}]
Input :
  - ModelConfig M
  - PersonaConfig P_cfg
  - BenchmarkFile F_bench
  - BenchmarkType T_bench   // "gsm8k" atau "mmlu"
  - Direktori keluaran D_out

Output:
  - Himpunan log L_JSON
  - Berkas summary.json

Prosedur RunBenchmarkBatch(M, P_cfg, F_bench, T_bench, D_out):

  1. persona_data  <- LoadJSON(P_cfg.file_path)
     persona_entry <- SelectPersona(persona_data, P_cfg.persona_id)
     persona_text  <- persona_entry.text

  2. system_prompt <- BuildSystemPrompt(M, persona_text)

  3. items <- LoadBenchmarkItems(F_bench, T_bench)
     Inisialisasi L_JSON <- {}
     Inisialisasi summary_rows <- []

  4. Untuk setiap item x dalam items:
        q_id <- x.id

        Jika T_bench == "gsm8k":
            q_stem <- x.question_text
            gold   <- x.reference_answer
            user_msg <- BuildUserPromptGSM8K(q_stem)

        Jika T_bench == "mmlu":
            q_stem  <- x.question_stem
            options <- x.options
            gold    <- x.correct_choice
            user_msg <- BuildUserPromptMMLU(q_stem, options)

        messages <- [
          { "role": "system", "content": system_prompt },
          { "role": "user",   "content": user_msg }
        ]

        t0       <- Now()
        response <- CallOpenRouterAPI(M.model_id, messages, M.extra_params)
        latency  <- Now() - t0

        resp_text <- ExtractText(response)

        Jika T_bench == "gsm8k":
            pred <- ExtractFinalAnswerGSM8K(resp_text)

        Jika T_bench == "mmlu":
            pred <- ExtractChoiceMMLU(resp_text)

        raw_record <- {
          "run": {
            "model_id":    M.name,
            "question_id": q_id,
            "persona":     P_cfg.persona_id
          },
          "request": {
            "system_prompt": system_prompt,
            "user_prompt":   user_msg
          },
          "response": response,
          "meta": { "latency_ms": latency * 1000 }
        }

        WriteJSON( JoinPath(D_out, q_id + ".json"), raw_record )
        Tambahkan raw_record ke L_JSON

        summary_row <- {
          "question_id": q_id,
          "gold_answer": gold,
          "predicted":   pred,
          "is_correct":  CompareAnswers(gold, pred, T_bench),
          "total_tokens":      SafeGet(response, "usage.total_tokens"),
          "prompt_tokens":     SafeGet(response, "usage.prompt_tokens"),
          "completion_tokens": SafeGet(response, "usage.completion_tokens"),
          "latency_ms":        latency * 1000
        }

        Tambahkan summary_row ke summary_rows

  5. summary <- {
       "model_name": M.name,
       "model_id":   M.model_id,
       "persona": {
         "source_file": P_cfg.file_path,
         "id":          P_cfg.persona_id,
         "text":        persona_text
       },
       "system_prompt": system_prompt,
       "items":         summary_rows
     }

     WriteJSON( JoinPath(D_out, "summary.json"), summary )
\end{lstlisting}

Pseudocode gabungan ini menunjukkan bagaimana pipeline menangani dua jenis \textit{benchmark} dengan struktur instruksi dan mekanisme ekstraksi jawaban yang berbeda, namun tetap mempertahankan alur eksekusi yang konsisten dan dapat direproduksi.


\subsection{Mekanisme Injeksi Konteks Persona}
\label{subsec:mekanisme-injeksi}

Mekanisme injeksi persona merupakan elemen penting untuk memastikan bahwa pengaruh persona terhadap keluaran model dapat diukur secara jelas. Pipeline menerapkan dua tahap injeksi konteks yang bersifat tetap dan hanya dilakukan satu kali untuk setiap persona sebelum rangkaian evaluasi dimulai.

Tahap pertama adalah \textit{persona context initialization}. Pada tahap ini, sistem menyusun \textit{system message} yang merangkum identitas dan karakter persona, baik dalam bentuk eksplisit maupun implisit sebagaimana didefinisikan pada Tabel~\ref{tab:user-persona}. Pesan ini berfungsi membangun \textit{cognitive framing} awal pada model sehingga konteks persona tertanam sebelum tugas utama diberikan.

Tahap kedua adalah \textit{persona warm-up message}. Pipeline mengirimkan satu interaksi pemanasan untuk memverifikasi bahwa respons model sudah mengikuti identitas dan gaya tutur persona tersebut. Respons dari tahap ini tidak digunakan dalam evaluasi, tetapi berfungsi sebagai pemeriksaan bahwa proses injeksi berhasil.

Setelah kedua tahap ini selesai, pipeline tidak lagi mengulangi injeksi persona untuk setiap pertanyaan. Identitas yang telah ditanamkan pada awal percakapan tetap digunakan selama seluruh rangkaian pengujian. Model kemudian langsung memproses seluruh soal pada GSM8K dan MMLU-Redux dalam kondisi persona yang sama. Pendekatan ini memastikan bahwa variasi keluaran model berasal dari perbedaan persona, bukan dari perbedaan struktur instruksi pada setiap soal.

\subsection{Alur Pelaksanaan Eksperimen}
\label{subsec:alur-operasional}


Secara operasional, pelaksanaan eksperimen mengikuti alur yang diringkas pada Gambar~\ref{fig:alur-eksperimen}. Diagram hierarki tersebut menunjukkan bagaimana berkas spesifikasi (\textit{spec}) menjadi titik awal yang menurunkan himpunan model, persona, dan benchmark, kemudian dikombinasikan menjadi skenario eksperimen yang dieksekusi oleh \textit{pipeline}.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{image/diagram-hierarki.png}
  \caption{Diagram hierarki spec, skenario eksperimen, dan pipeline eksekusi}
  \label{fig:alur-eksperimen}
\end{figure}

Alur operasional dapat diringkas dalam beberapa langkah berikut.

\begin{enumerate}
    \item Memuat spesifikasi eksperimen.\\
    Sistem membaca berkas \textit{spec} yang memuat daftar model, daftar persona, daftar benchmark (misalnya GSM8K dan MMLU-Redux), serta parameter eksekusi. Informasi ini menjadi \textit{single source of truth} bagi seluruh eksperimen.

    \item Membentuk ruang skenario eksperimen.\\
    Berdasarkan \textit{spec}, sistem membentuk himpunan skenario sebagai kombinasi \textit{multi model} $\times$ \textit{multi persona} $\times$ \textit{multi benchmark} beserta indeks soal. Setiap kombinasi disimpan sebagai satu \textit{configuration} yang akan dieksekusi.

    \item Menjalankan \textit{pipeline} untuk setiap skenario.\\
    Untuk setiap \textit{configuration}, sistem menerapkan persona (termasuk \textit{warm-up} jika digunakan), menyusun \textit{prompt} tugas dengan struktur yang seragam, lalu memanggil model melalui API. Jika terjadi kegagalan sementara, \textit{request} diulang hingga respons yang valid diperoleh atau batas percobaan tercapai.

    \item Mengevaluasi dan mencatat hasil.\\
    Respons model dievaluasi terhadap kunci jawaban atau label yang tersedia pada benchmark, kemudian disimpan bersama metadata penting seperti identitas model, persona, benchmark, jumlah token, dan waktu eksekusi.

    \item Mengulangi hingga seluruh skenario selesai.\\
    Proses pada butir sebelumnya diulang untuk seluruh \textit{configuration} dalam ruang eksperimen sampai semua kombinasi persona, model, dan benchmark dievaluasi.
\end{enumerate}

Dengan alur hierarkis ini, setiap hasil eksperimen dapat ditelusuri kembali ke \textit{spec} yang digunakan, sehingga pelaksanaan eksperimen bersifat terstruktur, dapat direproduksi, dan mudah diperluas.

%====== BAB IV.3 ======
\section{Integrasi Komponen Eksperimen}

Bagian ini menjelaskan komponen-komponen yang digunakan dalam eksperimen, yang terdiri atas \textit{benchmark} penalaran, himpunan model, struktur persona, ruang \textit{configuration}, serta contoh mekanisme injeksi persona. Seluruh komponen tersebut didefinisikan melalui berkas \textit{specification} sehingga dapat digunakan secara konsisten pada seluruh tahapan eksperimen.

\subsection{Benchmark Penalaran}

Eksperimen menggunakan dua \textit{benchmark} yang mewakili dua bentuk kemampuan penalaran.

\textit{Benchmark} pertama adalah \textit{GSM8K}, yang berisi soal cerita matematika tingkat sekolah menengah. \textit{Benchmark} ini menilai kemampuan sistem dalam melakukan penalaran numerik bertahap. Setiap soal memiliki jawaban numerik yang jelas sehingga pemeriksaan hasil dapat dilakukan secara deterministik \parencite{cobbe2021gsm8k}.

\textit{Benchmark} kedua adalah \textit{MMLU-Redux}, versi terkurasi dari MMLU yang memperbaiki ketidakkonsistenan format dan pilihan jawaban. \textit{Benchmark} ini digunakan untuk menilai penalaran lintas topik dalam format pilihan ganda, meliputi bidang sains, matematika, humaniora, dan ilmu sosial \parencite{mmluRedux2024dataset}.

Penggunaan kedua \textit{benchmark} tersebut memberikan cakupan dua bentuk penalaran yang berbeda, yaitu penalaran numerik prosedural dan penalaran konseptual deklaratif.

\subsection{Himpunan Model}

Eksperimen dijalankan pada beberapa model yang tersedia melalui layanan API. Model-model tersebut dipilih untuk memberikan keragaman arsitektur sehingga perbedaan respons yang muncul dapat dibandingkan lintas sistem. Model yang digunakan meliputi:

\begin{enumerate}
    \item Model komersial  
    GPT-5 Mini, Qwen 3 VL Instruct, Gemini 2.5 Flash, Llama 3.3 Nemotron Super 49B V1.5, Google Gemma 3n 4B, dan DeepSeek V3.2

    \item Model publik  
    Grok 4.1 Fast, NVIDIA Nemotron-nano-12B-v2-VL, dan Bert Nebulon Alpha.
\end{enumerate}

Keragaman ini memungkinkan analisis sensitivitas persona pada berbagai sistem dengan karakteristik yang berbeda.

\subsection{Struktur Persona}

Persona yang digunakan dalam eksperimen disusun berdasarkan enam dimensi: gender, usia, agama, pekerjaan, kewarganegaraan, dan register bahasa. Kombinasi dimensi tersebut menghasilkan lima belas persona yang mencakup persona eksplisit dan persona implisit, serta satu kondisi pengguna netral sebagai pembanding.

Tabel~\ref{tab:user-persona} menyajikan daftar lengkap persona yang digunakan.

\begin{table}[htbp]
\centering
\caption{Daftar persona pada kondisi eksperimen}
\label{tab:user-persona}
\renewcommand{\arraystretch}{1.15}

\resizebox{\textwidth}{!}{
\begin{tabular}{c l l l l l l l}
\toprule
\textbf{ID} &
\textbf{Persona} &
\textbf{Mode} &
\textbf{Gender} &
\textbf{Age Group} &
\textbf{Religion} &
\textbf{Occupation} &
\textbf{Nationality / Register} \\
\midrule
P1  & Implicit male baseline              & Implicit & Male   & -           & -        & -                & Neutral \\
P2  & Implicit female baseline            & Implicit & Female & -           & -        & -                & Neutral \\
P3  & Neutral user                        & Neutral  & -      & -           & -        & -                & Neutral \\
P4  & Indonesian Muslim young woman       & Explicit & Female & Young adult & Muslim   & Healthcare worker & Indonesian / Semi-formal \\
P5  & Indonesian Muslim young man         & Implicit & Male   & Young adult & Muslim   & Healthcare worker & Indonesian / Semi-formal \\
P6  & American middle-aged male           & Explicit & Male   & Middle-aged & Christian & Engineer         & American / Formal \\
P7  & American middle-aged female         & Implicit & Female & Middle-aged & Christian & Engineer         & American / Formal \\
P8  & Indonesian Gen-Z female             & Explicit & Female & Gen-Z       & -        & Student          & Indonesian / Casual-slang \\
P9  & Indonesian Gen-Z male               & Implicit & Male   & Gen-Z       & -        & Student          & Indonesian / Casual-slang \\
P10 & Middle Eastern young adult male     & Explicit & Male   & Young adult & Muslim   & Engineer         & Middle Eastern Arabic / Formal \\
P11 & Middle Eastern young adult female   & Implicit & Female & Young adult & Muslim   & Student          & Middle Eastern Arabic / Formal \\
P12 & American atheist young male         & Explicit & Male   & Young adult & Atheist  & Student          & American / Formal \\
P13 & American atheist young female       & Implicit & Female & Young adult & Atheist  & Student          & American / Formal \\
P14 & Indonesian female healthcare worker & Explicit & Female & Young adult & Muslim   & Healthcare worker & Indonesian / Semi-formal \\
P15 & Indonesian male healthcare worker   & Implicit & Male   & Young adult & Muslim   & Healthcare worker & Indonesian / Semi-formal \\
\bottomrule
\end{tabular}
}
\end{table}

\subsection{Struktur Konfigurasi Eksperimen}

Kombinasi lima belas persona dan sembilan model membentuk seratus tiga puluh lima \textit{configuration}. Setiap \textit{configuration} merepresentasikan satu pasangan persona dan model yang kemudian diuji pada himpunan \textit{task} yang sama. Dengan cara ini, variasi keluaran dapat dibandingkan pada dua tingkat, yaitu perbedaan antar persona dalam satu model dan perbedaan antar model pada persona yang sama.

Untuk menjaga keteraturan proses, setiap \textit{configuration} melewati urutan eksekusi yang tetap. Urutan tersebut meliputi penerapan persona pada awal percakapan, penyiapan konteks interaksi, pelaksanaan \textit{benchmark} pada himpunan soal yang telah ditetapkan, serta pencatatan hasil dan informasi pendukung. Pola yang berulang ini memudahkan penelusuran kembali setiap hasil ke persona, model, dan \textit{task} yang digunakan.

\subsection{Contoh Mekanisme Injeksi Persona}

Persona diterapkan melalui \textit{system message} yang dikirim sebelum \textit{task} utama diberikan. Dua bentuk persona digunakan dalam eksperimen, yaitu persona eksplisit dan persona implisit.

Pada persona eksplisit, identitas pengguna dinyatakan secara langsung melalui deskripsi. Instruksi ini menyebutkan atribut sosial yang relevan, seperti gender, usia, pekerjaan, atau preferensi gaya bahasa. Contoh yang digunakan dalam eksperimen adalah sebagai berikut.

\begin{quote}
\textit{
“Your user is an Indonesian Gen-Z male who works as a junior engineer.  
He is analytical, prefers concise explanations, and communicates in a casual but respectful tone.”}
\end{quote}

Formulasi seperti ini memberikan konteks identitas yang jelas sehingga perubahan pada struktur penalaran dan gaya jawaban dapat dikaitkan dengan persona yang digunakan.

Pada persona implisit, identitas tidak disebutkan secara langsung, tetapi ditampilkan melalui narasi pengalaman, ekspresi emosi, atau gaya tutur tertentu. Model menerima konteks ini sebagai bagian dari cerita pengguna dan perlu menyimpulkan sendiri karakter pengguna dari isyarat linguistik yang ada. Contoh yang digunakan dalam eksperimen adalah sebagai berikut.

\begin{quote}
\textit{
“Lately I have been feeling a strange mix of emotional exhaustion and pressure to appear composed, especially when my skin starts acting up unexpectedly. Before I deal with it again, could you help me break down this next question step-by-step?”}
\end{quote}

Kedua bentuk injeksi ini memungkinkan analisis perbedaan respons antara persona yang dinyatakan secara eksplisit dan persona yang hanya tersirat melalui cara pengguna menyampaikan situasi dan pertanyaannya.


%====== BAB IV.4 ======
\section{Perancangan Data dan Struktur Berkas}
\label{sec:perancangan-data-struktur}

Bagian ini menjelaskan rancangan data dan struktur berkas yang digunakan dalam eksperimen. Tujuan perancangan ini adalah agar keluaran dari setiap \textit{configuration} dapat dicatat secara teratur, ditelusuri kembali, dan dianalisis pada tahap berikutnya. Data yang digunakan dalam eksperimen dikelompokkan menjadi empat bagian utama, yaitu data konfigurasi, data \textit{benchmark}, data masukan tambahan, dan data hasil eksekusi.

Data konfigurasi disimpan di dalam direktori \texttt{config}. Direktori ini memuat berkas \textit{specification} yang menjadi dasar pembentukan ruang eksperimen, termasuk berkas \texttt{model.keys.json} yang berisi daftar model yang tersedia melalui layanan API, serta berkas lain yang memuat daftar \textit{persona}, daftar \textit{task}, dan parameter eksekusi. Perubahan terhadap ruang eksperimen dapat dilakukan dengan memodifikasi berkas-berkas pada direktori ini tanpa perlu mengubah kode program.

Data \textit{benchmark} disimpan di dalam direktori \texttt{data}. Direktori ini berisi \textit{dataset} yang digunakan dalam eksperimen, termasuk materi \textit{GSM8K} dan \textit{MMLU-Redux} dalam bentuk mentah maupun bentuk yang telah dinormalisasi untuk keperluan pemrosesan. Pemisahan ini membantu mendokumentasikan sumber data utama yang digunakan pipeline secara jelas.

Direktori \texttt{input} digunakan untuk menyimpan data pendukung yang tidak berasal dari \textit{benchmark} utama tetapi dibutuhkan selama eksperimen, seperti kumpulan soal yang dihasilkan ulang, daftar pertanyaan tambahan, atau berkas uji lain yang disiapkan secara terpisah dari \textit{dataset} utama. Pemisahan antara \texttt{data} dan \texttt{input} menjaga agar data asli dan data turunan tidak tercampur, serta memudahkan pelacakan asal setiap \textit{task} yang dieksekusi.

Dokumen pendukung, seperti catatan desain, skema eksperimen, dan dokumentasi penggunaan pipeline, disimpan pada direktori \texttt{docs}. Direktori ini tidak terlibat langsung dalam proses eksekusi, tetapi membantu proses audit dan pemeliharaan sistem di kemudian hari.

Hasil eksperimen disimpan di dalam direktori \texttt{results}. Direktori ini memuat berkas \textit{JSON} yang mencatat \textit{response} lengkap untuk setiap \textit{configuration}, termasuk \textit{instruction} yang digunakan, jawaban model, serta metadata yang dihasilkan selama eksekusi. Ringkasan hasil disimpan dalam bentuk \textit{CSV} untuk mempermudah proses analisis, misalnya perbandingan jawaban akhir, tingkat akurasi, jumlah token, atau latensi apabila informasi tersebut disediakan oleh layanan model.

Seluruh kode program ditempatkan dalam direktori \texttt{src}. Direktori ini berisi modul yang memuat \textit{specification}, menyusun \textit{instruction}, menjalankan \textit{task} untuk setiap \textit{configuration}, serta mencatat hasil eksekusi ke dalam \texttt{results}. Dengan pemisahan antara kode dan data, eksperimen dapat dijalankan kembali dengan pengaturan yang sama atau diperluas dengan \textit{specification} baru tanpa mengubah struktur direktori lainnya.

Dengan struktur direktori ini, setiap \textit{response} yang dihasilkan dapat ditelusuri kembali melalui \textit{persona}, model, dan \textit{task} yang digunakan. Perancangan ini mendukung kebutuhan replikasi eksperimen dan menjadi penghubung antara desain konseptual pada bagian sebelumnya dan analisis hasil pada bab berikutnya.

\subsection{Pseudocode Pengunduhan dan Normalisasi Benchmark}\par

Persiapan data \textit{benchmark} dilakukan melalui skrip
\texttt{gsm8k\_download.py} dan \texttt{mmlu\_redux\_download.py}. Kedua skrip ini
bertugas mengunduh dataset dari sumber resmi, menyimpannya pada direktori
\texttt{data}, dan menormalkan struktur data ke format yang konsisten sebelum
digunakan oleh pipeline.

Kode~\ref{lst:download-benchmarks} merangkum alur utama yang diimplementasikan
pada kedua skrip tersebut.

\begin{lstlisting}[caption={Pseudocode pengunduhan dan normalisasi benchmark},label={lst:download-benchmarks}]
Input :
  - URL_GSM8K_RAW
  - URL_MMLU_REDUX
  - Direktori data D_data

Output:
  - Berkas GSM8K terstruktur (gsm8k_normalized.json)
  - Berkas MMLU-Redux terstruktur (mmlu_redux_normalized.json)

Prosedur PrepareGSM8K(D_data):
  1. raw_file     <- DownloadFile(URL_GSM8K_RAW)
  2. parsed_items <- ParseRawGSM8K(raw_file)
  3. normalized   <- []
  4. Untuk setiap item dalam parsed_items lakukan:
       record <- {
         "id":            item.id,
         "question_text": item.question,
         "answer":        item.answer
       }
       Tambahkan record ke normalized
  5. out_path <- JoinPath(D_data, "gsm8k_normalized.json")
  6. WriteJSON(out_path, normalized)

Prosedur PrepareMMLURedux(D_data):
  1. raw_file     <- DownloadFile(URL_MMLU_REDUX)
  2. parsed_items <- ParseRawMMLU(raw_file)
  3. normalized   <- []
  4. Untuk setiap item dalam parsed_items lakukan:
       record <- {
         "id":            item.id,
         "subject":       item.subject,
         "question_stem": item.stem,
         "options":       item.options,
         "correct":       item.correct_option
       }
       Tambahkan record ke normalized
  5. out_path <- JoinPath(D_data, "mmlu_redux_normalized.json")
  6. WriteJSON(out_path, normalized)

Prosedur PrepareAllBenchmarks(D_data):
  1. EnsureDirExists(D_data)
  2. PrepareGSM8K(D_data)
  3. PrepareMMLURedux(D_data)
\end{lstlisting}

Melalui prosedur ini, seluruh \textit{benchmark} yang digunakan pipeline tersedia
dalam format terstruktur yang konsisten dan dapat diolah kembali apabila diperlukan.


%====== BAB IV.5 ======
\section{Penanganan Gangguan dan Pemulihan \textit{Execution Flow}}

Proses eksekusi melibatkan sejumlah besar kombinasi persona, model, dan \textit{task}, sehingga rentan terhadap gangguan yang bersumber dari layanan model maupun kondisi jaringan. Bagian ini menjelaskan mekanisme yang digunakan untuk mempertahankan keberlanjutan proses dan menjaga agar hasil yang diperoleh tetap konsisten serta dapat ditelusuri kembali.

Penanganan gangguan dilakukan dalam dua bentuk utama.

\begin{enumerate}
    \item \textit{Transient error handling}  
    Sistem mendeteksi gangguan sementara seperti \textit{timeout}, penolakan layanan, atau pemutusan koneksi. Jika gangguan terjadi, instruksi dijadwalkan ulang menggunakan jeda adaptif, sehingga proses tidak terhenti dan setiap \textit{configuration} tetap menghasilkan keluaran yang dapat dianalisis.

    \item \textit{Execution flow recovery}  
    Sistem mencatat status terakhir setiap kali respons berhasil diterima. Jika eksekusi terhenti sebelum seluruh \textit{configuration} selesai diproses, pipeline dapat dilanjutkan dari titik terakhir tanpa mengulang langkah yang telah berhasil. Dengan cara ini, proses panjang tetap dapat diselesaikan tanpa kehilangan progres.
\end{enumerate}

Kedua mekanisme tersebut menjaga stabilitas eksekusi pada skala besar dan memastikan bahwa alur eksperimen tetap dapat dipertanggungjawabkan pada tahap analisis.

\subsection{Pseudocode Pemantauan Checkpoint dan Pemulihan Eksekusi}

Penanganan gangguan pada pipeline didukung oleh dua skrip utama, yaitu \texttt{checkpoint\_monitor.py} dan \texttt{wait\_and\_report.py}.  
Skrip \texttt{checkpoint\_monitor.py} memantau progres eksekusi dan mencatat daftar \textit{configuration} yang telah menghasilkan keluaran lengkap.  
Skrip \texttt{wait\_and\_report.py} digunakan untuk memantau progres secara berkala dan melaporkan status eksekusi tanpa perlu membuka setiap berkas log secara manual.

Kode~\ref{lst:checkpoint-monitor} merangkum mekanisme pembaruan \textit{checkpoint}.

\begin{lstlisting}[caption={Pseudocode pemantauan checkpoint eksekusi},label={lst:checkpoint-monitor}]
Input :
  - Direktori hasil D_results
  - Daftar konfigurasi C (persona x model x task)

Output:
  - Berkas checkpoint (checkpoint.json)

Prosedur UpdateCheckpoint(D_results, C):
  1. completed <- Himpunan kosong

  2. Untuk setiap cfg dalam C lakukan:
       run_id   <- BuildRunId(cfg)
       log_path <- JoinPath(D_results, run_id, "summary.json")

       Jika FileExists(log_path):
         Tambahkan run_id ke completed

  3. checkpoint <- {
       "total_configurations": Panjang(C),
       "completed_runs":       completed,
       "remaining_runs":       (C \ completed),
       "last_update":          Now()
     }

  4. WriteJSON(JoinPath(D_results, "checkpoint.json"), checkpoint)
\end{lstlisting}

Pemantauan progres dilakukan melalui loop berkala sebagaimana diringkas pada Kode~\ref{lst:wait-and-report}.

\begin{lstlisting}[caption={Pseudocode pemantauan progres dan pelaporan},label={lst:wait-and-report}]
Input :
  - Direktori hasil D_results
  - Interval pemantauan Delta_t

Prosedur WaitAndReport(D_results, Delta_t):
  1. Loop tak hingga:

       checkpoint_path <- JoinPath(D_results, "checkpoint.json")

       Jika FileExists(checkpoint_path):
         cp        <- ReadJSON(checkpoint_path)
         total     <- cp.total_configurations
         completed <- Len(cp.completed_runs)
         remaining <- total - completed
         progress  <- completed / total

         Print("Progress:",
               completed, "/", total,
               "(remaining:", remaining, ",",
               "progress:", FormatPercent(progress), ")")

         Jika remaining == 0:
           Print("All configurations completed.")
           Keluar dari loop

       Tunggu selama Delta_t detik
\end{lstlisting}

Dengan mekanisme ini, eksekusi yang terhenti secara tidak terduga dapat dilanjutkan berdasarkan \textit{checkpoint} terakhir, dan progres keseluruhan dapat dipantau secara otomatis tanpa intervensi manual.


%====== BAB IV.6 ======
\section{Implementasi Keluaran Pipeline}
\label{sec:implementasi-keluaran}

Bagian ini menjelaskan bentuk keluaran yang dihasilkan oleh \textit{evaluation pipeline}
setelah seluruh tahap pemrosesan selesai dijalankan. Keluaran tersebut berfungsi sebagai
artefak utama yang dianalisis pada Bab~V. Seluruh hasil disimpan dalam direktori
\texttt{results} dalam format terstruktur sehingga setiap entri dapat ditelusuri kembali
ke persona, model, dan \textit{task} yang digunakan.

\subsection{Pseudocode Analisis Hasil dan Rekapitulasi}\par

Tahap pasca-proses hasil eksperimen direalisasikan melalui sejumlah skrip,
antara lain \texttt{parse\_gsm8k\_results.py}, \texttt{analyze\_results.py},
\texttt{analyze\_answers\_deep.py}, \texttt{generate\_results\_csv.py},
\texttt{quick\_summary.py}, dan \texttt{generate\_excel.py}.  
Skrip-skrip tersebut membaca log \texttt{JSON} per konfigurasi, menghitung metrik performa
(misalnya akurasi dan penggunaan token), lalu menyusun ringkasan dalam format
\texttt{CSV} dan \texttt{spreadsheet}.

Kode~\ref{lst:postprocessing} merangkum alur utama pasca-proses tersebut.

\begin{lstlisting}[caption={Pseudocode pasca-proses hasil eksperimen},label={lst:postprocessing}]
Input :
  - Direktori hasil D_results
  - Daftar konfigurasi C (persona x model x task)

Output:
  - Berkas CSV ringkasan per konfigurasi
  - Berkas Excel agregasi lintas model dan persona

Prosedur BuildPerConfigSummary(D_results, C):
  1. rows <- daftar kosong

  2. Untuk setiap cfg dalam C lakukan:
       run_id       <- BuildRunId(cfg)
       summary_path <- JoinPath(D_results, run_id, "summary.json")

       Jika FileExists(summary_path) == False:
         Lanjutkan ke konfigurasi berikutnya

       summary <- ReadJSON(summary_path)
       items   <- summary.items

       // Hitung metrik utama
       total_q    <- Len(items)
       correct_q  <- Count(item.is_correct untuk item dalam items)
       acc        <- correct_q / total_q

       total_tok  <- Sum(item.total_tokens untuk item dalam items jika tersedia)
       avg_tok    <- total_tok / total_q

       avg_lat_ms <- Mean(item.latency_ms untuk item dalam items)

       row <- {
         "model_name":      summary.model_name,
         "persona_id":      summary.persona.id,
         "task_type":       DetectTaskType(run_id),
         "total_questions": total_q,
         "correct":         correct_q,
         "accuracy":        acc,
         "avg_tokens":      avg_tok,
         "avg_latency_ms":  avg_lat_ms
       }

       Tambahkan row ke rows

  3. WriteCSV(JoinPath(D_results, "summary_per_config.csv"), rows)


Prosedur BuildExcelAggregation(D_results):
  1. csv_path <- JoinPath(D_results, "summary_per_config.csv")
  2. table    <- ReadCSV(csv_path)

  3. pivot_model_persona <- Pivot(
         data         = table,
         index        = ["model_name"],
         columns      = ["persona_id"],
         values       = ["accuracy"],
         agg_function = Mean
       )

  4. pivot_task <- Pivot(
         data         = table,
         index        = ["task_type"],
         columns      = ["model_name"],
         values       = ["accuracy"],
         agg_function = Mean
       )

  5. workbook <- CreateExcelWorkbook()
  6. AddSheet(workbook, "per_config",        table)
  7. AddSheet(workbook, "by_model_persona",  pivot_model_persona)
  8. AddSheet(workbook, "by_task_model",     pivot_task)
  9. SaveExcel(workbook,
               JoinPath(D_results,
                        "summary_aggregated.xlsx"))

Prosedur RunPostProcessing(D_results, C):
  1. BuildPerConfigSummary(D_results, C)
  2. BuildExcelAggregation(D_results)
\end{lstlisting}

Pseudocode ini menunjukkan bagaimana log mentah yang dihasilkan oleh pipeline
dikonversi menjadi ringkasan numerik yang kemudian digunakan dalam analisis pada Bab~V.

\subsection{Contoh Struktur Log Inferensi}

Setiap interaksi antara pipeline dan model dicatat dalam berkas \texttt{JSON}.
Berkas ini mencakup identitas konfigurasi, isi permintaan, jawaban model, serta
telemetri penggunaan token. Kode~\ref{lst:log-inferensi} menunjukkan contoh log untuk model
yang tidak menyediakan \textit{reasoning trace}.

\begin{lstlisting}[caption={Contoh struktur log inferensi}, label={lst:log-inferensi}]
{
  "run": {
    "model_id": "example-model",
    "question_id": "gsm8k_00001",
    "persona": "implicit_male"
  },
  "response": {
    "choices": [
      {
        "message": {
          "content": "Let's break down the problem..."
        }
      }
    ],
    "usage": {
      "prompt_tokens": 211,
      "completion_tokens": 197,
      "total_tokens": 408
    }
  },
  "meta": {
    "latency_ms": 842,
    "timestamp": "2025-01-18T12:44:10Z"
  }
}
\end{lstlisting}

\subsection{Contoh Struktur Log dengan Reasoning Trace}

Beberapa model menyediakan bagian penalaran (\textit{reasoning trace}) selain jawaban akhir.
Bagian ini disimpan sebagai elemen terpisah di dalam log. Kode~\ref{lst:log-reasoning}
menampilkan struktur log lengkap dari model yang menyediakan informasi tersebut.

\begin{lstlisting}[caption={Contoh struktur log dengan reasoning trace}, label={lst:log-reasoning}]
{
  "run": {
    "model_id": "example-model-reason",
    "question_id": "gsm8k_00003",
    "persona": "explicit_genz_female"
  },
  "response": {
    "choices": [
      {
        "message": {
          "content": "Final answer: 70000",
          "reasoning": "First compute the purchase cost..."
        }
      }
    ],
    "usage": {
      "completion_tokens": 867,
      "reasoning_tokens": 485,
      "total_tokens": 1352
    }
  },
  "meta": {
    "latency_ms": 2134,
    "timestamp": "2025-01-18T12:52:41Z"
  }
}
\end{lstlisting}

Log seperti ini memungkinkan analisis lebih dalam mengenai gaya penalaran
serta perubahan struktur argumen yang mungkin dipengaruhi oleh persona.

\subsection{Ringkasan Hasil Eksperimen}

Pipeline menghasilkan ringkasan performa dalam bentuk tabel yang menggabungkan
metrik akurasi dan penggunaan token untuk setiap pasangan persona--model. Berkas
ringkasan disimpan dalam format \texttt{CSV} untuk memudahkan analisis lanjutan.
Tabel berikut merupakan contoh representasi ringkasan hasil.

\begin{table}[htbp]
\centering
\caption{Contoh ringkasan hasil eksperimen GSM8K untuk seluruh model dan persona}
\label{tab:gsm8k-summary-compact}
\renewcommand{\arraystretch}{1.15}
\footnotesize
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{l l c c c c}
\toprule
\textbf{Model} &
\textbf{Persona} &
\textbf{Total Q} &
\textbf{Correct} &
\textbf{Accuracy (\%)} &
\textbf{Total Tokens} \\
\midrule
Bert Nebulon Alpha & man\_implicit   & 610  & 593  & 97.21 & 285250 \\
Bert Nebulon Alpha & woman\_implicit & 641  & 627  & 97.26 & 335208 \\
\midrule
Grok 4.1 Fast & man\_implicit   & 1315 & 1242 & 94.45 & 1325229 \\
Grok 4.1 Fast & woman\_implicit & 1316 & 1254 & 95.36 & 1422736 \\
\midrule
Nvidia Nemotron 12B v2 VL & man\_implicit   & 1305 & 1224 & 93.79 & 1156049 \\
Nvidia Nemotron 12B v2 VL & woman\_implicit & 1306 & 1230 & 94.18 & 1184521 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}


