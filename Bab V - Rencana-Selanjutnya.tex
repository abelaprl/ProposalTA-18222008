% ==========================================
% BAB V RENCANA SELANJUTNYA
% ==========================================
\chapter{RENCANA SELANJUTNYA}
\label{chap:rencana-selanjutnya}


\section{Rencana Implementasi dan Estimasi Biaya} 
\label{sec:rencana-implementasi-biaya}

Rencana implementasi pada tahap berikutnya adalah menjalankan kembali
\textit{evaluation pipeline} yang telah dijelaskan pada Bab~IV dengan cakupan
penuh, yang meliputi sembilan model bahasa, dua \textit{benchmark} penalaran
(GSM8K dan MMLU-Redux), serta lima belas \textit{user persona} (implisit,
eksplisit, dan netral). Bagian ini merumuskan langkah implementasi teknis,
asumsi kebutuhan token, serta estimasi biaya penggunaan API berdasarkan harga
resmi masing-masing model pada platform OpenRouter%

Estimasi dilakukan menggunakan kurs konstan 1 USD = Rp16.000.

% -------------------------------------------------------------
% 5.1.1 Rencana Implementasi Eksperimen
% -------------------------------------------------------------
% -------------------------------------------------------------
% 5.1.1 Rencana Implementasi Eksperimen
% -------------------------------------------------------------
\subsection{Rencana Implementasi Eksperimen}

Pelaksanaan eksperimen direncanakan mengikuti enam langkah utama berikut.

\begin{enumerate}
  \item Persiapan aset data.\\
  Sistem memuat berkas definisi lima belas persona, korpus GSM8K (split
  \textit{test}), MMLU-Redux (20 subjek), kredensial API, serta konfigurasi
  model. Struktur direktori dan modul pemrosesan mengikuti rancangan pada
  Subbab~\ref{sec:perancangan-data-struktur}.

  \item Inisialisasi dan \textit{warm-up} persona.\\
  Setiap model menerima satu pesan awal untuk menanamkan konteks persona
  sebelum mengerjakan soal pertama. Tahap ini juga berfungsi sebagai
  \textit{sanity check} untuk memastikan bahwa model mengikuti identitas dan
  gaya bahasa persona secara konsisten.

  \item Eksekusi eksperimen utama.\\
  Setiap kombinasi model--persona menjalankan seluruh soal GSM8K dan
  MMLU-Redux menggunakan mekanisme injeksi pesan berbasis peran:
  persona pada \textit{system message} dan soal pada \textit{user message}.
  Setiap respons diharuskan menyertakan penalaran langkah demi langkah.

  \item Pencatatan log granular.\\
  Seluruh respons disimpan sebagai berkas JSON yang memuat isi \textit{prompt},
  jawaban mentah, \textit{token usage}, serta \textit{latency}. Format ini
  memastikan bahwa setiap respons dapat ditelusuri kembali ke konfigurasi yang
  digunakan.

  \item Agregasi dan validasi hasil.\\
  Log yang terkumpul diubah menjadi berkas CSV agregat yang berisi akurasi,
  rata-rata latensi, serta total konsumsi token. Validasi tambahan dilakukan
  melalui pemeriksaan pola jawaban dan konsistensi jumlah entri.

  \item Penanganan kegagalan.\\
  Kegagalan akibat \textit{timeout} atau batas \textit{rate limit} ditangani
  menggunakan mekanisme \textit{retry} dengan \textit{exponential backoff},
  sebagaimana dijelaskan pada Bab~IV. Dengan demikian, kegagalan sebagian
  tidak menghentikan keseluruhan eksperimen.
\end{enumerate}



% -------------------------------------------------------------
% 5.1.2 Himpunan Model dan Skenario Eksekusi
% -------------------------------------------------------------
\subsection{Himpunan Model dan Skenario Eksekusi}

Eksperimen ini menggunakan sembilan model dengan rincian sebagai berikut.

\begin{enumerate}
  \item Enam model berbayar (via OpenRouter):
  \begin{enumerate}
    \item openai/gpt-5-mini
    \item anthropic/claude-haiku-4.5
    \item google/gemini-2.5-flash
    \item deepseek/deepseek-v3.2
    \item nvidia/llama-3.3-nemotron-super-49b-v1.5
    \item google/gemma-3n-e4b-it
  \end{enumerate}

  \item Tiga model yang pada saat perancangan tersedia sebagai \textit{free-tier}:
  \begin{enumerate}
    \item xai/grok-4.1-fast
    \item nvidia/nemotron-nano-12b-v2-vl
    \item openrouter/bert-nebulon-alpha
  \end{enumerate}
\end{enumerate}

Seluruh sembilan model dijalankan pada konfigurasi penuh: dua
\textit{benchmark} dan lima belas persona. Namun, estimasi biaya hanya
dihitung untuk enam model berbayar.

% -------------------------------------------------------------
% 5.1.3 Asumsi Jumlah Soal dan Kebutuhan Token
% -------------------------------------------------------------
\subsection{Asumsi Jumlah Soal dan Kebutuhan Token}

Kebutuhan token dihitung berdasarkan dua sumber utama:
GSM8K (1319 soal) dan MMLU-Redux (2000 soal).
Pada kedua \textit{benchmark}, model diarahkan untuk memberikan
penalaran lengkap sebelum jawaban akhir, sehingga konsumsi token per soal
diharapkan berada pada kisaran yang relatif tinggi.

\begin{enumerate}
  \item GSM8K.

  Total token per persona per model diestimasikan sebagai:
  \[
    T_{\text{GSM8K}} \approx
    1319 \times 1200
    = 1{,}582{,}800 \text{ token}.
  \]

  \item MMLU-Redux.

  Total token per persona per model diestimasikan sebagai:
  \[
    T_{\text{MMLU}} \approx
    2000 \times 1200
    = 2{,}400{,}000 \text{ token}.
  \]
\end{enumerate}

Total token inti per persona diperoleh dari penjumlahan keduanya:
\[
  T_{\text{base, persona}} =
  1{,}582{,}800 + 2{,}400{,}000
  = 3{,}982{,}800.
\]

Untuk mengakomodasi \textit{warm-up} dan \textit{retry}, digunakan faktor
overhead 20\%:
\[
  T_{\text{persona}} \approx
  1.2 \times 3{,}982{,}800
  = 4{,}779{,}360.
\]

Sehingga total token per model untuk 15 persona adalah:
\[
  T_{\text{model}}
  \approx 15 \times 4{,}779{,}360
  = 71{,}690{,}400
  \approx 71{,}7 \times 10^6.
\]

Komposisi token diasumsikan:
\[
  T_{\text{in}} = 0.4T_{\text{model}},\qquad
  T_{\text{out}} = 0.6T_{\text{model}}.
\]

% -------------------------------------------------------------
% 5.1.4 Estimasi Biaya per Model
% -------------------------------------------------------------
\subsection{Estimasi Biaya per Model}

Harga token per model mengacu pada dokumentasi OpenRouter%
\parencite{openrouter_gpt5mini,openrouter_claudehaiku45,openrouter_gemini25flash,
openrouter_deepseek32,openrouter_llama33,openrouter_gemma3n}.  
Biaya untuk model ke-$m$ dihitung dengan rumus:
\[
  \text{cost}_m =
  p_{\text{in},m} \times \frac{T_{\text{in}}}{10^6}
  +
  p_{\text{out},m} \times \frac{T_{\text{out}}}{10^6},
\]
dengan $p_{\text{in},m}$ dan $p_{\text{out},m}$ adalah harga per satu juta
token untuk \textit{input} dan \textit{output}.

Estimasi berikut menggunakan kurs Rp\,16.000 per USD dan total token
$T_{\text{model}} \approx 71{,}7 \times 10^6$.

\begin{table}[htbp]
\centering
\caption{Estimasi biaya enam model berbayar untuk konfigurasi penuh 15 persona}
\label{tab:estimasi_biaya_model}

\renewcommand{\arraystretch}{1.22}
\footnotesize
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{l c c c}
\toprule
\textbf{Model} &
\textbf{Total Token} $T_{\text{model}}$ &
\textbf{Biaya (USD)} &
\textbf{Biaya (Rp)} \\
\midrule
openai/gpt-5-mini & $\approx 71{,}7 \times 10^6$ & 93.20  & $\approx 1{,}491{,}000$ \\
anthropic/claude-haiku-4.5 & $\approx 71{,}7 \times 10^6$ & 243.75 & $\approx 3{,}900{,}000$ \\
google/gemini-2.5-flash & $\approx 71{,}7 \times 10^6$ & 116.14 & $\approx 1{,}858{,}000$ \\
deepseek/deepseek-v3.2 & $\approx 71{,}7 \times 10^6$ & 24.95  & $\approx 399{,}000$ \\
nvidia/llama-3.3-nemotron-super-49b-v1.5 & $\approx 71{,}7 \times 10^6$ & 20.07  & $\approx 321{,}000$ \\
google/gemma-3n-e4b-it & $\approx 71{,}7 \times 10^6$ & 2.29   & $\approx 37{,}000$ \\
\midrule
\textbf{Total enam model berbayar} & -- & \textbf{500.40} & $\approx \textbf{8{,}006{,}000}$ \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

Tiga model lain yang tersedia sebagai \textit{free-tier}
(grok-4.1-fast, nemotron-nano-12b-v2-vl, dan bert-nebulon-alpha)
diperkirakan mengonsumsi token serupa tetapi tidak menimbulkan biaya
finansial langsung. Status \textit{free-tier} tersebut tetap harus
diverifikasi kembali sebelum eksperimen akhir dijalankan.

Dengan demikian, estimasi total biaya finansial untuk menjalankan seluruh
eksperimen multi-model, multi-persona, dan dua \textit{benchmark} penalaran
adalah sekitar 500,40 USD atau kurang lebih 8 juta rupiah. Angka ini
bersifat konservatif karena telah memasukkan biaya \textit{warm-up}
dan \textit{retry}, sehingga realisasi biaya dapat lebih rendah apabila
konsumsi token aktual per soal ternyata lebih kecil dari asumsi yang
digunakan dalam perhitungan ini.

\section{Desain Pengujian dan Evaluasi}
\label{sec:desain-pengujian-evaluasi}

Desain pengujian pada tahap berikut disusun untuk memastikan bahwa seluruh
hasil eksperimen dapat diverifikasi, divalidasi, dan direplikasi. Struktur
pengujian memanfaatkan artefak log granular, telemetry penggunaan token,
serta pemeriksaan konsistensi yang telah ditanamkan dalam pipeline pada Bab~IV.

\begin{enumerate}

  \item Verifikasi konsistensi eksekusi.

  Verifikasi dilakukan untuk memastikan bahwa setiap model menerima stimulus
  yang identik pada setiap soal dan persona, sehingga variasi respons dapat
  dikaitkan langsung dengan perbedaan persona atau arsitektur model.

  (i) Konsistensi konstruksi prompt.

  Pemeriksaan dilakukan untuk memastikan bahwa struktur persona pada
  \textit{system message} dan isi soal pada \textit{user message} identik pada
  seluruh eksekusi. Setiap variasi kecil seperti pergeseran tanda baca atau
  perubahan format dapat mengubah jalur penalaran model, sehingga pemeriksaan
  dilakukan secara programatik pada log JSON.

  (ii) Kesesuaian urutan eksekusi.

  Pemeriksaan dilakukan dengan mencocokkan indeks interaksi, nomor soal,
  dan urutan persona pada seluruh berkas log untuk memastikan bahwa sistem
  menjalankan eksperimen sesuai konfigurasi yang direncanakan.

  (iii) Keberhasilan tahap warm-up.

  Tahap warm-up diverifikasi dengan menilai apakah respons awal model
  mengikuti identitas dan gaya bahasa persona. Kegagalan tahap ini dicatat
  sebagai anomali dan disertai eksekusi ulang sebelum proses utama dimulai.

  \item Validasi keluaran model.

  Validasi keluaran bertujuan memastikan bahwa jawaban model berada dalam
  format yang sesuai untuk dievaluasi. Pendekatan validasi dibedakan untuk
  GSM8K dan MMLU-Redux.

  (i) Validasi GSM8K.

  Model harus memberikan jawaban numerik akhir yang dapat diekstraksi secara
  deterministik. Selain itu, respons harus mencakup penalaran langkah demi
  langkah sebelum menyatakan jawaban akhir.

  (ii) Validasi MMLU-Redux.

  Model harus memberikan pilihan jawaban dalam format A, B, C, atau D. Meskipun
  merupakan soal pilihan ganda, model tetap diminta menjelaskan penalaran
  sebelum memilih opsi, sehingga respons memiliki struktur yang konsisten.

  (iii) Pemeriksaan konsistensi format respons.

  Pemeriksaan mencakup panjang respons, struktur teks, keberadaan penalaran,
  serta keterbacaan sehingga setiap respons dapat diproses ulang tanpa kesalahan
  parsing.

  \item Evaluasi kuantitatif.

  Evaluasi kuantitatif dilakukan untuk mengukur dampak persona terhadap performa
  model pada dua benchmark.

  (i) Akurasi jawaban.

  Akurasi dihitung dengan membandingkan jawaban akhir yang diekstraksi terhadap
  ground truth. Penghitungan dilakukan pada tabel agregasi hasil.

  (ii) Konsumsi token.

  Evaluasi melibatkan token input, token output, dan token penalaran sebagai
  indikator beban komputasi dan kecenderungan verbosity model di bawah persona
  tertentu.

  (iii) Latensi eksekusi.

  Latensi diambil dari metadata waktu pada log JSON untuk menilai stabilitas
  waktu respons model ketika menangani beban besar dan variasi persona.

\end{enumerate}

%========= V.3 Analisis Risiko dan Mitigasi ==========

\section{Analisis Risiko dan Mitigasi}
Pelaksanaan eksperimen pada lingkungan multi-model dan multi-persona menimbulkan sejumlah risiko metodologis dan operasional yang perlu dikelola secara sistematis agar integritas penelitian tetap terjaga. Risiko-risiko tersebut mencakup aspek reliabilitas penggunaan API, kestabilan keluaran model, konsistensi proses penalaran, menjaga ketepatan pesan sepanjang percakapan, serta akurasi proses agregasi data. Selain itu, penelitian sebelumnya menunjukkan bahwa konsistensi LLM dapat menurun pada evaluasi berskala besar dan bahwa penalaran model dapat terpengaruh oleh faktor-faktor non-linguistik yang tidak terkontrol. Berdasarkan temuan tersebut, bagian ini menguraikan tiga kategori risiko utama serta strategi mitigasinya.

\begin{enumerate}
  \item Risiko kegagalan pemanggilan API.
  
  Risiko ini mencakup galat seperti \textit{timeout}, gangguan koneksi, dan pembatasan layanan (rate limit). Kegagalan ini berpotensi menyebabkan hilangnya sebagian data atau ketidaksinkronan indeks percobaan.

  (i) Mitigasi dilakukan melalui mekanisme \textit{retry} adaptif berbasis \textit{exponential backoff}, sesuai praktik standar pada sistem terdistribusi.

  (ii) Seluruh kegagalan direkam dalam log terpisah untuk memastikan keterlacakan sehingga perbaikan atau pengulangan dapat dilakukan secara selektif.

  (iii) Tingkat konkurensi dijalankan secara otomatis ketika sistem mendeteksi peningkatan laju galat, guna menjaga stabilitas kapasitas layanan.

  \item Risiko lonjakan konsumsi token.
  
  LLM sering menghasilkan keluaran yang lebih panjang daripada yang diinstruksikan, terutama ketika diminta memberikan penalaran langkah demi langkah. Fenomena ini berdampak langsung pada biaya dan durasi eksperimen.

  (i) Sistem membatasi panjang keluaran dengan parameter \textit{maximum completion length} untuk mencegah respons berlebihan.

  (ii) Validasi awal dijalankan secara berkala untuk memantau rata-rata konsumsi token per soal.

  (iii) Persona yang terbukti memicu keluaran terlalu panjang dilakukan penyesuaian instruksi secara minimal untuk mengendalikan panjang teks tanpa mengubah maksud identitas sosial.

  \item Risiko penyimpanan dan konsistensi log.
  
  Volume log yang besar berpotensi menimbulkan risiko korupsi berkas dan ketidakcocokan antara indeks model, persona, dan soal.

  (i) Setiap respons disimpan dalam format terstruktur (JSON) dengan skema tetap.

  (ii) Proses agregasi mengadopsi pemeriksaan konsistensi silang antara jumlah entri dan indeks soal.

  (iii) Mekanisme \textit{checkpointing} diterapkan untuk menghindari kehilangan data apabila eksekusi terhenti di tengah proses.
\end{enumerate}
